{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-25T14:03:07.716644Z","iopub.execute_input":"2022-01-25T14:03:07.71738Z","iopub.status.idle":"2022-01-25T14:03:07.730201Z","shell.execute_reply.started":"2022-01-25T14:03:07.717314Z","shell.execute_reply":"2022-01-25T14:03:07.729073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install --upgrade plotly ","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:07.732373Z","iopub.execute_input":"2022-01-25T14:03:07.73308Z","iopub.status.idle":"2022-01-25T14:03:07.738053Z","shell.execute_reply.started":"2022-01-25T14:03:07.733026Z","shell.execute_reply":"2022-01-25T14:03:07.736956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's import the libraries\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport plotly.express as px\nimport seaborn as sns\nfrom pandas_profiling import ProfileReport\nfrom scipy.stats import ttest_ind\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import tree\nfrom sklearn.metrics import plot_roc_curve, f1_score, recall_score\nfrom sklearn.model_selection import RandomizedSearchCV","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:07.742433Z","iopub.execute_input":"2022-01-25T14:03:07.743214Z","iopub.status.idle":"2022-01-25T14:03:07.756389Z","shell.execute_reply.started":"2022-01-25T14:03:07.743159Z","shell.execute_reply":"2022-01-25T14:03:07.755427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Style des graphiques seaborn\nsns.set_theme(style = \"whitegrid\")","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:07.758412Z","iopub.execute_input":"2022-01-25T14:03:07.761975Z","iopub.status.idle":"2022-01-25T14:03:07.771512Z","shell.execute_reply.started":"2022-01-25T14:03:07.761916Z","shell.execute_reply":"2022-01-25T14:03:07.770538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_stroke = pd.read_csv(\"/kaggle/input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:07.773242Z","iopub.execute_input":"2022-01-25T14:03:07.773849Z","iopub.status.idle":"2022-01-25T14:03:07.805053Z","shell.execute_reply.started":"2022-01-25T14:03:07.773805Z","shell.execute_reply":"2022-01-25T14:03:07.804038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_frame = data_stroke.copy()","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:07.806818Z","iopub.execute_input":"2022-01-25T14:03:07.80739Z","iopub.status.idle":"2022-01-25T14:03:07.812246Z","shell.execute_reply.started":"2022-01-25T14:03:07.807348Z","shell.execute_reply":"2022-01-25T14:03:07.81143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n<div style=\"font-family: 'Times New Roman'\" align=\"justify\"><h1 align=\"center\" class=\"alert alert-info\">DEMARCHE DE TRAVAIL</h1>\n<h2 align=\"center\" class=\"alert alert-success\">OBJECTIF MESURABLE</h2>\n    <strong>OBJECTIF</strong>\n<p>Prédire si une personne est atteinte d'un accident vasculaire cérébral ou pas à partir des données personnelles et cliniques fournies (problème de classification). Il est essentiel de noter qu'il est plus urgent, dans ce cas de figure, de détecter toutes les personnes malades (et non ceux qui sont vraiment malades parmi ceux qui sont identifiés comme malade). Sinon un patient malade peut être diagnostiquer comme sain alors que ce n'est pas le cas. Nous préférerons ainsi la sensibilité/spécificité à la précision.</p></li><hr size = \"2\">\n    <strong>METRIQUE ET SCORE A ATTEINDRE</strong> \n<p>La proportion de la classe positive est largement inférieure à la proportion de la classe négative (nous notons une forte déséquilibre de classes). Dans ce cas de figure, la métrique accuracy ne sera pas assez performante pour évaluer notre modèle de classification. A la place, nous allons utiliser les métriques sensibilité et précision pour valider notre modèle :</p>\n<ul>\n    <li>Sensibilité : $\\frac{VP}{VP+FN}$. Elle permet de calculer le pourcentage de tests positifs parmi les patients réellement atteints d'AVC ;</li>\n    <li>Spécificité : $\\frac{VN}{VN+FP}$. Elle permet de calculer le pourcentage de tests négatifs parmi les patients réellement sains. C'est la sensibilité pour les test négatifs ;</li>\n    <li>Précision : $\\frac{VP}{VP+FP}$. Elle permet de calculer le pourcentage de patients réellement malades parmi ceux dont le test est positif ;</li>\n    <li>F1-score : $\\frac{2\\times Sensibilite \\times Precision}{Sensibilite+Precision}$ ;</li>\n    <li>\n        Avec :\n        <ul>\n            <li>$VP$ : Nombre de Vrais Positifs ;</li>\n            <li>$VN$ : Nombre de Vrais Négatifs ;</li>\n            <li>$FN$ : Nombre de Faux Négatifs ;</li>\n            <li>$FP$ : Nombre de Faux Positifs ;</li>\n        </ul>\n    </li>\n </ul>   \n<p>Nous nous fixons une sensibilité/spécificité supérieure à <strong>80%</strong>. Nous pouvons également utiliser des outils supplémentaires comme <strong>les courbes ROC et Precision-Recall</strong> pour affiner nos choix de performance.</p>\n<h2 align=\"center\" class=\"alert alert-success\">EXPLORATION DES DONNEES</h2>\n<h3 align=\"center\" class=\"alert alert-warning\" style=\"color:darkorange\">ANALYSE DE LA FORME</h3>\n<strong>CIBLE</strong>\n<p>La variable dépendante est la variable <strong>stroke</strong> qui contient des données discrètes. Cette variable indique si une personne est atteinte d'un accident vasculaire cérébral (1 pour atteinte) ou pas (0 pour non atteinte). Nous allons abréger, par la suite, accident vasculaire cérébral par AVC pour faciliter l'écrit. Nous devons transformer, plus tard, la variable cible en variable catégorielle non ordinale (cela nous permettra de différencier la catégorie \"être atteint(e) d'AVC\" de la catégorie \"être non atteint(e) d'AVC\"). Nous devrons ainsi utiliser un modèle de classification (classification model) pour déterminer si un patient est malade ou sain.</p>\n<hr size=\"2\">\n<strong>NOMBRE DE LIGNES ET DE COLONNES</strong> \n<p>Nous avons identifié 5110 observations et 12 variables (dont la cible). Le nombre d'observations est inférieur à 10000, donc notre dataset ne contient pas énormément d'observations mais assez pour entraîner un modèle.</p>\n<hr size=\"2\">\n<strong>TYPES DE VARIABLES</strong>\n<p>Parmi les variables explicatives, nous avons identifié 7 variables catégorielles (dont deux contiennent des valeurs discrètes et les autres contiennent des valeurs de type chaîne de caractères) et 3 variables non catégorielles.</p>\n<ul>\n    <li>\n        Les variables de type object ont pour valeurs possibles les suivantes :\n        <ul>\n            <li><strong>gender</strong> (genre) : contient les valeurs <i>Male</i> (Homme), <i>Female</i> (Femelle) ou <i>Other</i> (ni Homme, ni Femme) ;</li>\n            <li><strong>ever_married</strong> (jamais marié(e)) : peut prendre les valeurs <i>Yes</i> (Oui) ou <i>No</i> (Non) ;</li>\n            <li><strong>work_type</strong> (type de travail) : peut prendre les valeurs <i>Private</i> (Privée), <i>Self_employed</i> (Auto emploi ou Travail autonome), <i>Govt_job</i> (Travail au gouvernement), <i>children</i> (enfant), <i>Never_worked</i> (N'a jamais travaillé(e)) ;</li>\n            <li><strong>Residence_type</strong> (type de résidence) : peut prendre les valeurs <i>Urban</i> (Urbaine), <i>Rural</i> (Rurale) ;</li>\n            <li><strong>smoking_status</strong> (statut de fumeur) : contient les valeurs <i>formerly_smoked</i> (a fumé(e) dans le passé), <i>never_smoke</i> (n'a jamais fumé), <i>smokes</i> (fume), <i>Unknow</i> (donnée non recueillie).</li>\n        </ul>\n    </li>\n    <li>Quant aux variables catégorielles <strong>hypertension</strong> et <strong>heart_disease</strong> (maladie de coeur), elles peuvent prendre les valeurs 1 (pour <i>positive</i>) ou 0 (pour <i>négative</i>). </li>\n    <li>Nous identifions une variable discrète non categorielle (<strong>age</strong>) dont les valeurs varient de 0.08 (enfant de 9 mois) à 82 (adulte de 82 ans). Sa valeur moyenne est de 43 (adulte de 43 ans).</li>\n    <li>\n        Le dataset ne contient que deux variables continues, <strong>avg_glucose_level</strong> (niveau moyen de glucose dans le sang) et <strong>bmi</strong> (indice de masse corporelle). Ces deux variables ne s'expriment pas avec les mêmes unités :\n        <ul>\n            <li>La variable avg_glucose_level a pour valeur maximale 271.74 et pour valeur minimale 55.12. Sa valeur moyenne est de 106.15.</li>\n            <li>La variable bmi a pour valeur maximale 97.60 et pour valeur minimale 10.30. Sa valeur moyenne est 28.89.</li>\n        </ul>\n    </li>\n    <li>Nous définirons plus en détail ces variables dans la partie analyse du fond.</li>\n</ul>\n<hr size=\"2\">\n<strong>IDENTIFICATION DES VALEURS MANQUANTES</strong>\n<p>Nous remarquons que seule la variable bmi contient des valeurs manquantes qui sont un peu dispersées dans le dataset (Un peu entassées au niveau des premières observations). Mais en sachant que le nombre de valeurs manquantes ne représente que 16% dans l'ensemble des données présentes dans la colonne bmi et que nous allons choisir un échantillon aléatoire pour l'entraînement du modèle (ainsi que pour l'évaluation) donc on peut supposer que le remplacement des valeurs manquantes par la valeur la plus fréquente dans la variable bmi constitue une bonne stratégie.</p>\n<hr size=\"2\">\n<strong>IDENTIFICATION DES VALEURS REDONDANTES</strong>\n<p>Les données ne contiennent pas d'observations dupliquées.</p>\n<h3 align=\"center\" class=\"alert alert-warning\" style=\"color:darkorange\">ANALYSE DU FOND</h3>\n<strong>VISUALISATION DE LA CIBLE</strong>\n<p>Nous remarquons que 95.13% des patients sont atteintes d'AVC contre seulement 4.87% des patients atteintes d'AVC. La proportion de patients non malades est largement supérieure au nombre de patients non malades.</p>\n<hr size=\"2\">\n<strong>COMPREHENSION DES DIFFERENTES VARIABLES</strong> \n<ul>\n    <li>id : La variable id contient des valeurs discrètes et identifie chaque observation de manière unique. Elle n'apporte aucune information supplémentaire et donc n'influence pas le fait qu'une personne soit malade ou non. La variable id doit être supprimée.</li>\n    <li>\n        Variables catégorielles :\n        <ul>\n            <li>Hypertension : Cette variable indique si oui ou non, le patient souffre d'hypertension. Un patient est testé positif à l'hypertension si on constate à deux reprises, et pas dans le même jour, une tension systolique supérieure ou égale à 140 mm Hg et/ou une tension diastolique supérieure ou égale à 90 mm Hg. Selon les tests cliniques, une hypertension peut souvent être la cause d'AVC. Nous verrons par la suite si les données recueillies de cette variable sont fiables. La colonne hypertension contient 90% de tests négatifs et 10% de tests positifs.</li>\n            <li>heart_disease : La variable heart_disease indique si le patient est atteint de cardiopathie (maladie cardiaque) ou pas. Il y a différents types de cardiopathies et nous verrons si ces derniers peuvent influencer le risque d'attraper un AVC. La colonne heart_disease contient 95% de tests positifs contre seulement 5% de tests négatifs. Cependant, nous savons que l'hypertension non traitée peut causer la cardiopathie. Donc on peut supposer, d'ores et déjà, que ces deux variables sont fortement corrélées (hypothèse à vérifier).</li>\n            <li>gender : La variable gender indique à quel sexe appartient le patient. On doit vérifier si le sexe du patient peut influencer le risque qu'il soit atteint d'AVC. La colonne gender est composée de 58% de femmes, de 41% d'hommes et très peu (presque 0%) de sexe de type autre.</li>\n            <li>ever_married : Cette variable indique si le patient a déjà été marié. L'analyse de cette variable doit nous permettre de dire si le patient a plus de chance d'attraper un AVC en s'étant déjà marié (dans le temps présent ou passé) ou pas. Nous notons 66% des patients qui se sont jamais mariés et 34% qui se sont déjà mariés. </li>\n            <li>work_type : Elle indique le type de travail effectué par un patient. On identifie 57% de patients travaillant dans le secteur privé (professions et secteurs d'activité ne dépendant pas de l'Etat), 16% des patients effectuant du travail autonome (ils sont leurs propres employés), 13% des patients sont des enfants (on n'a pas plus d'informations sur la catégorie children mais on suppose pour l'instant que le patient est un enfant et donc qu'il n'a pas besoin de travailler), presque 13% des patients travaillent pour le gouvernement (dans le secteur public) et seulement 0.4% n'ont jamais travaillé. Pour les patients dont le type de travail est children, nous devons vérifier si leurs âges indiquent que ce sont des enfants ou pas (c'est-à-dire certains sont des adultes).</li>\n            <li>residence_type : Cette variable indique le type de résidence du patient. 51% des patients résident dans un milieu urbain (ville) et 49% des patients résident dans un milieu rural (campagne). Les proportions de ces deux classes sont presque similaires.</li>\n            <li>smoking_status : Elle indique si le patient est/était un fumeur ou pas. 37% des patients n'ont jamais fumé, 30% des patients n'indiquent pas s'ils fument, 17% des patients ont fumé auparavant et 15% des patients disent fumer au moment où on les interrogeait. La catégorie unknow (inconnue) peut constituer un problème car elle n'apporte aucune information utile. Nous vérifierons par la suite si cette variable apporte de l'information à notre modèle.</li>\n        </ul>\n    </li>\n    <li>\n        Variables non catégorielles :\n        <ul>\n            <li>age : Nous constatons que les patients qui sont âgés entre 37 et 63 ans sont plus nombreux dans la base de données, suivis des patients qui sont âgés entre 78 et 82 ans tandis que les plus jeunes sont les moins nombreux.</li>\n            <li>avg_glucose_level : Le niveau moyen de glucose dans le sang indique si, oui ou non, le patient est atteint de diabète. Cette variable s'exprime en mg/dL (milligrammes par décilitre). Les patients qui souffrent de diabète ont un niveau moyen de glucose supérieur ou égale à 200 mg/dL. Par contre, un niveau moyen de glucose, inférieur à 140 mg/dL, est considéré comme normal. Nous constatons que la plupart des patients n'ont pas de diabète car une grande partie des patients ont un niveau moyen de glucose tournant autour de 75-87 mg/dL de sang. Nous remarquons qu'environ 10 à 20% des patients ont un niveau moyen de glucose tournant autour de 210-225 mg/dL. On peut considérer que ces derniers sont atteints de diabète.</li>\n            <li>bmi : L'indice de masse corporelle (IMC) permet d'indiquer la corpulence d'un patient. Il s'exprime en kg/m2 (kilogrammes par mètre carré). Une personne est considérée comme obèse si son IMC dépasse 30 kg/m2. La plupart des patients examinés ont un IMC situé autour de 29 kg/m2. Ces derniers présentent un cas de surpoids ou d'obésité modérée (dont les IMC sont respectivement situés entre 25 et 30 kg/m2 et entre 30 et 35 kg/m2).</li>\n        </ul>\n    </li>\n</ul>\n<hr size=\"2\">\n<strong>ETUDE PLUS POUSSEE DES VARIABLES AVEC PANDAS-PROFILING</strong> ##\n<hr size=\"2\">\n<strong>VISUALISATION DES RELATIONS ENTRE LES VARIABLES EXPLICATIVES ET LA CIBLE </strong>\n<ul>\n    <li>\n        Relations Cible - variables catégorielles :\n        <ul>\n            <li>Pour la variable work_type : Nous remarquons que les patients qui ont pour type de travail children ont plus de chance de ne pas attraper d'AVC que les patients qui effectuent d'autres types de travail. On a peu de patients non travailleurs dans la variable work_type donc on ne peut rien dire par rapport à cette catégorie (mais il est possible qu'elle influence aussi le fait qu'on soit atteint d'AVC ou pas).</li>\n            <li>Pour la variable smoking_type : Nous remarquons que les patients ne disant pas s'ils fument/fumaient présentent une proportion de malades inconsistante par rapport aux autres types de fumeurs. Cela est dû au fait que la catégorie unknow n'est pas fiable (elle se comporte comme une valeur manquante).</li>\n        </ul>\n    </li>\n    <li>\n        Relations Cible - Variables non catégorielles :\n        <ul>\n            <li>Parmi les variables non catégorielles, seule la variable âge influence le fait qu'un patient soit atteint d'AVC ou pas. Il y a plus de risque d'attraper un AVC chez les patients plus âgés ;</li>\n            <li>Pour les deux autres variables restantes nous constatons que les distributions sont presque les mêmes pour les patients malades et non malades ;</li>\n            <li>Nous vérifierons plus amplement ces hypothèses à travers un test de student.</li>\n        </ul>\n    </li>\n</ul>\n<hr size=\"2\">\n<strong>VISUALISATION DES RELATIONS ENTRE VARIABLES QUANTITATIVES</strong>\n<p>Les variables quantitatives ne partagent aucune forte corrélation entre elles.</p>\n<hr size=\"2\">\n<strong>VISUALISATION DES RELATIONS ENTRE VARIABLES CATEGORIELLES ET QUANTITATIVES</strong>\n<p>Nous constatons que quelques variables catégorielles ont de fortes corrélations avec des variables quantitatives.</p>\n<ul>\n    <li>La variable <strong>age</strong> est fortement corrélée avec les variables <strong>work_type</strong>, <strong>smoking_status</strong> et <strong>ever_married</strong>. Pour sa relation avec les autres variables catégorielles nous remarquons de légères corrélations ou quasiment pas de corrélations pour certaines.</li>\n    <li>La variable <strong>bmi</strong> est, pour son cas, fortement corrélée avec les variables <strong>ever_married</strong> et <strong>work_type</strong>.</li>\n    <li>En revenant au niveau de pandas profiling, nous constatons que nos analyses sont soutenues par les remarques faites par la librairie (aucune incohérence n'est à noter).</li>\n</ul>\n<hr size=\"2\">\n<strong>IDENTIFICATION DES VALEURS ABERRANTES</strong>\n<p>Tous les trois variables comportent des valeurs aberrantes (anormales).</p>\n<ul>\n    <li>La variable age ne comporte que deux valeurs aberrantes du coté de la classe <i>test positif</i> de la variable stroke ;</li>\n    <li>Les variables bmi et avg_glucose_level contiennent plusieurs valeurs aberrantes.</li>\n    <li>La variable avg_glucose_level ne contient des valeurs aberrantes que du coté de la classe <i>test negatif</i> de la variable stroke alors que la variable bmi en comporte pour les deux classes (mais beaucoup plus du coté de la classe <i>test negatif</i>).</li>\n</ul>\n<hr size=\"2\">\n<strong>PREMIERE CONCLUSION</strong> \n<ul>\n    <li>On constate une dépendance entre la variable cible et la variable age.</li>\n    <li>La variable id ne comporte aucune information utile donc il est préférable de la supprimer de la base de données.</li>\n    <li>La base de données contient des valeurs manquantes que nous allons remplacer par la valeur la plus fréquente de la variable bmi ;</li>\n    <li>La catégorie unknow de la variable smoking_status n'apporte aucune information supplémentaire donc nous devons la remplacer par une catégorie plus intéressante (<i>never smoked</i> par exemple) ;</li>\n    <li>Les variables quantitatives ne sont pas corrélées entre elles ;</li>\n    <li>La variable age est fortement corrélée avec certaines variables catégorielles. Notamment les variables work_type, ever_married et smoking_status ;</li>\n    <li>La variable bmi est aussi fortement corrélée avec les variables catégorielles ever_married et work_type ;</li>\n    <li>Nous devons garder les variables age et bmi et supprimer les variables smoking_status, work_type et ever_married ;</li>\n    <li>Des tests supplémentaires seront réalisé pour étayer certaines hypothèses ou les rejeter ;</li>\n    <li>Les variables quantitatives comportent des valeurs aberrantes. Nous allons vérifier s'il est nécessaire de les remplacer ou de les supprimer (il serait mieux de les supprimer pour ne pas changer la distribution de nos variables) ;</li>\n    <li>Nous allons retenir pour l'instant les variables hypertension et heart_disease qui sont cliniquement très intéressantes pour nos analyses.</li>\n</ul>\n<hr size=\"2\">\n<strong>TESTS D'HYPOTHESES</strong>\n<p>Ces tests nous permettrons de valider ou de rejeter certaines hypothèses.</p>\n<ul>\n    <li>\n        Testons si les variables quantitatives influencent le fait qu'un patient soit atteint d'AVC ou pas (nous noterons H0 l'hypothèse selon laquelle une variable n'a pas d'influence sur la cible) :\n        <ul>\n             <li>Le test de student nous indique que les variables <strong>age</strong> et <strong>avg_glucose_level influencent le fait qu'un patient soit atteint d'AVC ou pas</strong>.</li>\n            <li>La variable <strong>bmi n'entretient pas de dépendance avec la variable stroke</strong>.</li>\n        </ul>\n    </li>\n</ul>\n<hr size=\"2\">\n<strong>SECONDE CONCLUSION</strong> \n<ul>\n    <li>Les variables age et avg_glucose_level apportent de l'information contrairement à la variable bmi qui elle peut-être supprimée.</li>\n    <li>Les variables à supprimer sont donc : bmi, work_type, ever_married, smoking_status, id. Pour le moment nous ne supprimerons que ces variables. Nous ferons une sélection antérieure de variables si on constate un over-fitting sur les données de test.</li>\n</ul>\n</div>","metadata":{}},{"cell_type":"markdown","source":"<h1 align=\"center\" class=\"alert alert-info\">Exploration des données</h1>","metadata":{}},{"cell_type":"markdown","source":"<h2 align=\"center\" class=\"alert alert-success\">Identification de la cible</h2>","metadata":{}},{"cell_type":"code","source":"# Vérifions le contenu des dix premières lignes  \ndata_frame.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:07.813916Z","iopub.execute_input":"2022-01-25T14:03:07.814462Z","iopub.status.idle":"2022-01-25T14:03:07.839656Z","shell.execute_reply.started":"2022-01-25T14:03:07.81442Z","shell.execute_reply":"2022-01-25T14:03:07.838628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\">Nous savons que la cible est la variable stroke. C'est la variable à expliquer.</p>","metadata":{}},{"cell_type":"code","source":"# Déterminons le type de la cible et son contenu\n# Type de la variable\ndata_frame[\"stroke\"].dtype","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:07.841313Z","iopub.execute_input":"2022-01-25T14:03:07.841899Z","iopub.status.idle":"2022-01-25T14:03:07.848588Z","shell.execute_reply.started":"2022-01-25T14:03:07.841854Z","shell.execute_reply":"2022-01-25T14:03:07.847931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Vérifions les valeurs possibles du target\ndata_frame[\"stroke\"].unique()","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:07.850052Z","iopub.execute_input":"2022-01-25T14:03:07.850594Z","iopub.status.idle":"2022-01-25T14:03:07.862252Z","shell.execute_reply.started":"2022-01-25T14:03:07.85055Z","shell.execute_reply":"2022-01-25T14:03:07.861562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 align=\"center\" class=\"alert alert-success\">Nombre de ligne et de colonnes</h2>","metadata":{}},{"cell_type":"code","source":"# Forme du dataframe\ndata_frame.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:07.863856Z","iopub.execute_input":"2022-01-25T14:03:07.86445Z","iopub.status.idle":"2022-01-25T14:03:07.87345Z","shell.execute_reply.started":"2022-01-25T14:03:07.864402Z","shell.execute_reply":"2022-01-25T14:03:07.872431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\">Nous avons 5110 observations et 12 variables (dont la cible)</p>","metadata":{}},{"cell_type":"markdown","source":"<h2 align=\"center\" class=\"alert alert-success\">Types des variables explicatives</h2>","metadata":{}},{"cell_type":"code","source":"# Identifions les types des variables\ndata_frame.dtypes","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:07.875617Z","iopub.execute_input":"2022-01-25T14:03:07.875935Z","iopub.status.idle":"2022-01-25T14:03:07.886846Z","shell.execute_reply.started":"2022-01-25T14:03:07.8759Z","shell.execute_reply":"2022-01-25T14:03:07.885956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\">Nous identifions 7 colonnes de type catégorielles. Nous allons stocker les noms de ces colonnes dans une variable.</p>","metadata":{}},{"cell_type":"code","source":"categorical_columns = [\"hypertension\", \"heart_disease\"]\ncategorical_columns.extend(data_frame.select_dtypes('object').columns)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:07.888171Z","iopub.execute_input":"2022-01-25T14:03:07.888387Z","iopub.status.idle":"2022-01-25T14:03:07.896957Z","shell.execute_reply.started":"2022-01-25T14:03:07.888362Z","shell.execute_reply":"2022-01-25T14:03:07.896335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Pour chaque variable de type object vérifions ses catégories\nfor column in data_frame.select_dtypes('object').columns:\n    print(f\"Valeurs uniques de {column:-<20} {data_frame[column].unique()}\\n\")","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:07.89809Z","iopub.execute_input":"2022-01-25T14:03:07.89894Z","iopub.status.idle":"2022-01-25T14:03:07.916713Z","shell.execute_reply.started":"2022-01-25T14:03:07.898898Z","shell.execute_reply":"2022-01-25T14:03:07.915647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Vérifions les valeurs que contient les variables hypertension et heart_disease\nfor column in categorical_columns[:2]:\n    print(f\"Unique values of {column:-<20} {data_frame[column].unique()}\\n\")","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:07.918003Z","iopub.execute_input":"2022-01-25T14:03:07.919875Z","iopub.status.idle":"2022-01-25T14:03:07.926236Z","shell.execute_reply.started":"2022-01-25T14:03:07.919829Z","shell.execute_reply":"2022-01-25T14:03:07.925358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\">Stockons dans une autre variable les noms des colonnes non catégorielles.</p>","metadata":{}},{"cell_type":"code","source":"non_categorical_columns = [\"age\", \"avg_glucose_level\", \"bmi\"]","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:07.927358Z","iopub.execute_input":"2022-01-25T14:03:07.927566Z","iopub.status.idle":"2022-01-25T14:03:07.936856Z","shell.execute_reply.started":"2022-01-25T14:03:07.927539Z","shell.execute_reply":"2022-01-25T14:03:07.936236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Vérifions les statistiques des colonnes non catégorielles\ndata_frame[non_categorical_columns].describe()","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:07.93785Z","iopub.execute_input":"2022-01-25T14:03:07.93822Z","iopub.status.idle":"2022-01-25T14:03:07.963537Z","shell.execute_reply.started":"2022-01-25T14:03:07.938174Z","shell.execute_reply":"2022-01-25T14:03:07.962718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 align=\"center\" class=\"alert alert-success\">Identification des valeurs manquantes</h2>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\">Première analyse des valeurs manquantes par sommation.</p>","metadata":{}},{"cell_type":"code","source":"data_frame.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:07.964922Z","iopub.execute_input":"2022-01-25T14:03:07.965137Z","iopub.status.idle":"2022-01-25T14:03:07.974002Z","shell.execute_reply.started":"2022-01-25T14:03:07.965104Z","shell.execute_reply":"2022-01-25T14:03:07.972958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Stockage du dataframe des données manquantes dans une variable\nna_values = data_frame.isna()","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:07.975144Z","iopub.execute_input":"2022-01-25T14:03:07.975743Z","iopub.status.idle":"2022-01-25T14:03:07.98342Z","shell.execute_reply.started":"2022-01-25T14:03:07.975704Z","shell.execute_reply":"2022-01-25T14:03:07.982798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\">Deuxième analyse par visualisation (Visualisation de la répartition des valeurs manquantes dans le dataset).</p>","metadata":{}},{"cell_type":"code","source":"px.imshow(na_values)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:07.984281Z","iopub.execute_input":"2022-01-25T14:03:07.984816Z","iopub.status.idle":"2022-01-25T14:03:08.034936Z","shell.execute_reply.started":"2022-01-25T14:03:07.984786Z","shell.execute_reply":"2022-01-25T14:03:08.034059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\">Nous remarquons que seule la variable bmi contient des valeurs manquantes qui sont un peu dispersées dans le dataset (Un peu entassées au niveau des premières observations).</p>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\">Vérifions le pourcentage de valeurs manquantes.</p>","metadata":{}},{"cell_type":"code","source":"percentage_of_na = na_values[\"bmi\"].sum()/data_frame.shape[1]","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:08.036479Z","iopub.execute_input":"2022-01-25T14:03:08.036991Z","iopub.status.idle":"2022-01-25T14:03:08.042806Z","shell.execute_reply.started":"2022-01-25T14:03:08.036949Z","shell.execute_reply":"2022-01-25T14:03:08.041885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"La variable bmi contient {percentage_of_na}% de valeurs manquantes.\")","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:08.044171Z","iopub.execute_input":"2022-01-25T14:03:08.044783Z","iopub.status.idle":"2022-01-25T14:03:08.053997Z","shell.execute_reply.started":"2022-01-25T14:03:08.044738Z","shell.execute_reply":"2022-01-25T14:03:08.053009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 align=\"center\" class=\"alert alert-success\">Identification des observations redondantes</h2>","metadata":{}},{"cell_type":"code","source":"# Vérifions s'il y a des observations dupliquées dans le dataset\ndata_frame.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:08.063023Z","iopub.execute_input":"2022-01-25T14:03:08.063509Z","iopub.status.idle":"2022-01-25T14:03:08.075524Z","shell.execute_reply.started":"2022-01-25T14:03:08.063465Z","shell.execute_reply":"2022-01-25T14:03:08.074807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\">Le dataset ne contient pas d'observations dupliquées.</p>","metadata":{}},{"cell_type":"markdown","source":"<h2 align=\"center\" class=\"alert alert-success\">Visualisation de la cible</h2>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\">Nous devons voir la proportion de chaque classe au sein de la variable cible pour identifier si on a affaire à un désiquilibre de classe.</p>","metadata":{}},{"cell_type":"code","source":"# Vérifions la proportion de chaque classe\nproportions = data_frame[\"stroke\"].value_counts(normalize = True)*100\nproportions","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:08.0768Z","iopub.execute_input":"2022-01-25T14:03:08.07732Z","iopub.status.idle":"2022-01-25T14:03:08.085132Z","shell.execute_reply.started":"2022-01-25T14:03:08.07729Z","shell.execute_reply":"2022-01-25T14:03:08.084494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\">Visualisons la proportion de chaque classe à l'aide d'un diagramme en camembert.</p>","metadata":{}},{"cell_type":"code","source":"proportions.plot.pie(labels=[\"Sans AVC\", \"Avec AVC\"])\nplt.title(\"Diagramme en camembert de stroke\")\nplt.ylabel('')","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:08.086172Z","iopub.execute_input":"2022-01-25T14:03:08.087007Z","iopub.status.idle":"2022-01-25T14:03:08.17924Z","shell.execute_reply.started":"2022-01-25T14:03:08.086973Z","shell.execute_reply":"2022-01-25T14:03:08.17837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\">Nous remarquons que 95.13% des personnes sont atteintes d'AVC contre seulement 4.87% de personnes atteintes d'AVC.</p>","metadata":{}},{"cell_type":"code","source":"# Transformation en variable catégorielle de la cible\ndata_frame[\"stroke\"] = data_frame[\"stroke\"].astype(\"category\")","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:08.180728Z","iopub.execute_input":"2022-01-25T14:03:08.181598Z","iopub.status.idle":"2022-01-25T14:03:08.187855Z","shell.execute_reply.started":"2022-01-25T14:03:08.181552Z","shell.execute_reply":"2022-01-25T14:03:08.186939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 align=\"center\" class=\"alert alert-success\">Compréhension des différentes variables</h2>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\">Analysons les variables à l'aide de graphiques.\nNous devons d'abord transformer les types ('object' et 'int') des variables catégorielles en type 'category' pour faciliter les analyses.</p>","metadata":{}},{"cell_type":"code","source":"# Transformation en type category de tous les variables catégorielles\nfor column in categorical_columns:\n    data_frame[column] = data_frame[column].astype('category')","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:08.189158Z","iopub.execute_input":"2022-01-25T14:03:08.18977Z","iopub.status.idle":"2022-01-25T14:03:08.209989Z","shell.execute_reply.started":"2022-01-25T14:03:08.189718Z","shell.execute_reply":"2022-01-25T14:03:08.208894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_frame[categorical_columns].dtypes","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:08.211446Z","iopub.execute_input":"2022-01-25T14:03:08.211847Z","iopub.status.idle":"2022-01-25T14:03:08.221624Z","shell.execute_reply.started":"2022-01-25T14:03:08.211801Z","shell.execute_reply":"2022-01-25T14:03:08.220892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3 align=\"center\" class=\"alert alert-warning\">Variables catégorielles</h3>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\">Identifions la proportion de chaque classe.</p>","metadata":{}},{"cell_type":"code","source":"# Récupérons les proportions des variables dans une liste\nproportions = []\nfor column in categorical_columns:\n    proportion = data_frame[column].value_counts(normalize = True)*100\n    proportions.append(proportion)\n    print(f\"Colonne {column} :\\n{proportion}\\n-------------------\\n\")","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:08.222805Z","iopub.execute_input":"2022-01-25T14:03:08.223387Z","iopub.status.idle":"2022-01-25T14:03:08.243491Z","shell.execute_reply.started":"2022-01-25T14:03:08.223346Z","shell.execute_reply":"2022-01-25T14:03:08.242649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tracons le diagramme en barres des proportions pour chaque variable\nfig, axs = plt.subplots(4, 2, figsize = (16, 14))\naxs = axs.flat\n\nfor i, p in enumerate(proportions):\n    fig.tight_layout(pad = 3)\n    sns.barplot(x = p.index, y = p.values, ax = axs[i])\n    axs[i].set_title(f\"Diagramme en barres {p.name}\")\n    axs[i].set_xlabel(p.name)\n    axs[i].set_ylabel(\"Pourcentages de valeurs\")\n    \nfig.delaxes(axs[7])\n    ","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:08.24466Z","iopub.execute_input":"2022-01-25T14:03:08.244882Z","iopub.status.idle":"2022-01-25T14:03:10.686335Z","shell.execute_reply.started":"2022-01-25T14:03:08.244856Z","shell.execute_reply":"2022-01-25T14:03:10.685306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3 align=\"center\" class=\"alert alert-warning\">Variables non catégorielles</h3>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\">Comptons le nombre de patients par age à l'aide d'un countplot.</p>","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (17, 17))\nsns.countplot(data = data_frame, y = \"age\", palette = \"viridis\")\nplt.title(\"Nombre de patients par age\")","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:10.687987Z","iopub.execute_input":"2022-01-25T14:03:10.688915Z","iopub.status.idle":"2022-01-25T14:03:12.090693Z","shell.execute_reply.started":"2022-01-25T14:03:10.688872Z","shell.execute_reply":"2022-01-25T14:03:12.089852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\">Nous constatons qu'il y a plus de patients adultes que de patients jeunes. Le plus grand nombre de tests a été effectué sur les personnes agées de 78 ans. Visualisons la distribution de la variable age.</p>","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (15, 8))\nsns.histplot(data = data_frame, x = \"age\", kde = True)\nplt.title(\"Distribution de la variable age\")","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:12.092162Z","iopub.execute_input":"2022-01-25T14:03:12.092591Z","iopub.status.idle":"2022-01-25T14:03:12.399434Z","shell.execute_reply.started":"2022-01-25T14:03:12.092553Z","shell.execute_reply":"2022-01-25T14:03:12.39848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\">La variable age ne suit pas une distribution normale. Nous remarquons que la distribution est plus élevée au niveau des patients âgés entre 37 et 63 ans. Elle est moins élevée au niveau des jeunes patients.</p>\n","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\">Traçons les histogrammes du niveau moyen de glucoses dans le sang et celui de l'indice de masse corporelle.\n</p>","metadata":{}},{"cell_type":"code","source":"fig, axs = plt.subplots(1, 2, figsize = (17, 6))\n\naxs = axs.flat\n\nfor i, column in enumerate(non_categorical_columns[-2:]):\n    fig.tight_layout(w_pad = 3, pad = 1.2)\n    color = \"green\" if i == 0 else \"blue\" \n    sns.histplot(data = data_frame, x = column, kde = True, ax = axs[i], color = color)\n    ","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:12.401225Z","iopub.execute_input":"2022-01-25T14:03:12.401527Z","iopub.status.idle":"2022-01-25T14:03:13.207606Z","shell.execute_reply.started":"2022-01-25T14:03:12.401485Z","shell.execute_reply":"2022-01-25T14:03:13.206731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\">Nous remarquons, pour la variable avg_glucose_level, une composition de deux distributions (la deuxième à l'aire de se détacher de la première). La première distribution ressemble à une distribution normale avec une plus grande variance que la deuxième et sa moyenne tourne autour de 75-87 mg/dL de sang. Pour la deuxième distribution, dont la variance est plus faible, nous notons une moyenne tournant autour de 210-225 mg/dL.</p>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\">Nous remarquons, pour la variable bmi, une distribution qui semble être normale avec une moyenne tournant autour de 30 kg/m2.</p>","metadata":{}},{"cell_type":"markdown","source":"<h2 align=\"center\" class=\"alert alert-success\">Utilisation de Pandas Profiling</h2>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\">Utilisons la librairie pandas profiling pour affiner nos analyses.</p>","metadata":{}},{"cell_type":"code","source":"profile = ProfileReport(data_frame, title = \"Investigation avec Pandas Profiling\")","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:13.209159Z","iopub.execute_input":"2022-01-25T14:03:13.209496Z","iopub.status.idle":"2022-01-25T14:03:13.216822Z","shell.execute_reply.started":"2022-01-25T14:03:13.209465Z","shell.execute_reply":"2022-01-25T14:03:13.216181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# profile","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:13.217928Z","iopub.execute_input":"2022-01-25T14:03:13.218625Z","iopub.status.idle":"2022-01-25T14:03:13.231623Z","shell.execute_reply.started":"2022-01-25T14:03:13.218585Z","shell.execute_reply":"2022-01-25T14:03:13.230849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\">Nous reviendrons à quelques remarques effectuées par pandas profiling plus tard. Nous pouvons passer à l'analyse des relations entre les variables.</p>","metadata":{}},{"cell_type":"markdown","source":"<h2 align=\"center\" class=\"alert alert-success\">Relations entre la cible et les variables explicatives</h2>","metadata":{}},{"cell_type":"markdown","source":"<h3 align=\"center\" class=\"alert alert-warning\">Variables catégorielles / cible</h3>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\">Analysons ces relations en utilisant les tableaux croisés (de comptage).</p>","metadata":{}},{"cell_type":"code","source":"# Affichons des tableaux croisés entre la cible et chaque variable catégorielle à l'aide d'un heatmap.\n\nfig, axs = plt.subplots(4, 2, figsize = (20, 16), sharey = True)\naxs = axs.flat\n\nfor i, column in enumerate(categorical_columns):\n    fig.tight_layout(pad = 3, h_pad = 4)\n    sns.heatmap(pd.crosstab(data_frame[\"stroke\"], data_frame[column]), annot = True, fmt = \"d\", ax = axs[i])\n    axs[i].set_title(f\"Tableau croisé entre stroke et {column}\", fontsize = 15)\n    axs[i].set_xlabel(column, fontsize = 13)\n    \nfig.delaxes(axs[7])","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:13.232636Z","iopub.execute_input":"2022-01-25T14:03:13.233182Z","iopub.status.idle":"2022-01-25T14:03:17.04491Z","shell.execute_reply.started":"2022-01-25T14:03:13.233147Z","shell.execute_reply":"2022-01-25T14:03:17.044082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\">Nous remarquons que pour la variable work_type, on a une proportion de patients malades moins importante au niveau de la catégorie children.\nNous remarquons également que pour la variable smoking_status, la proportion de patients malades est moins importante au niveau de la catégorie unknown. Pour le reste des variables nous ne notons pas de différences considérables entre les différentes proportions.</p>","metadata":{}},{"cell_type":"markdown","source":"<h3 align=\"center\" class=\"alert alert-warning\">Variables non catégorielles / variable cible</h3>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\">Dans cette partie, nous devons affiner les analyses effectuées sur les variables non catégorielles en tracant des distributions suivant les différentes classes possibles de la variable cible. Nous verifierons ensuite si les distributions obtenues sont semblables.</p>","metadata":{}},{"cell_type":"markdown","source":"**Pour la variable age**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (15, 6))\nsns.histplot(data = data_frame, x = \"age\", hue = \"stroke\", kde = True, palette = \"tab10\")\nplt.title(f\"Histogramme de la variable age\", fontsize = 14)\nplt.xlabel(\"age\", fontsize = 13)\nplt.ylabel(\"stroke\", fontsize = 12)\nplt.tight_layout(pad = 5)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:17.0463Z","iopub.execute_input":"2022-01-25T14:03:17.046597Z","iopub.status.idle":"2022-01-25T14:03:17.48496Z","shell.execute_reply.started":"2022-01-25T14:03:17.046559Z","shell.execute_reply":"2022-01-25T14:03:17.484262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\">Nous voyons que les deux distributions sont différentes. Nous constatons que les personnes plus agées ont plus de risque d'être atteintes d'AVC.</p>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\"><strong>Pour la variable avg_glucose_level</strong></p>","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (15, 8))\nsns.histplot(data = data_frame, x = \"avg_glucose_level\", hue = \"stroke\", kde = True, palette = \"tab10\")\nplt.title(f\"Histogramme de la variable avg_glucose_level\", fontsize = 14)\nplt.xlabel(\"avg_glucose_level\", fontsize = 13)\nplt.ylabel(\"stroke\", fontsize = 12)\nplt.tight_layout(pad = 5)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:17.486231Z","iopub.execute_input":"2022-01-25T14:03:17.486828Z","iopub.status.idle":"2022-01-25T14:03:18.216542Z","shell.execute_reply.started":"2022-01-25T14:03:17.486778Z","shell.execute_reply":"2022-01-25T14:03:18.215709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\">Nous remarquons une différence entre les deux distributions qui ne semble pas très visible.</p>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\"><strong>Pour la variable bmi</strong>. Nous pouvons remplacer les valeurs manquantes de la variable par la valeur la plus fréquente (mode).</p>","metadata":{}},{"cell_type":"code","source":"mode = data_frame[\"bmi\"].mode()\ndata_to_plot = data_frame.fillna(mode)\nplt.figure(figsize = (15, 8))\nsns.histplot(data = data_to_plot, x = \"bmi\", hue = \"stroke\", kde = True, palette = \"tab10\")\nplt.title(f\"Histogramme de la variable bmi\", fontsize = 14)\nplt.xlabel(\"bmi\", fontsize = 13)\nplt.ylabel(\"stroke\", fontsize = 12)\nplt.tight_layout(pad = 5)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:18.217786Z","iopub.execute_input":"2022-01-25T14:03:18.218018Z","iopub.status.idle":"2022-01-25T14:03:19.049953Z","shell.execute_reply.started":"2022-01-25T14:03:18.21799Z","shell.execute_reply":"2022-01-25T14:03:19.048905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\">Nous obtenons à peu près les mêmes distributions pour les deux classes de la cible.</p>","metadata":{}},{"cell_type":"markdown","source":"<h2 align=\"center\" class=\"alert alert-success\">Relations entre variables non catégorielles</h2>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\">Vérifions si certaines variables non catégorielles ont une forte corrélation entre elles.</p>","metadata":{}},{"cell_type":"code","source":"# px.imshow(data_frame[non_categorical_columns].corr().round(2), text_auto = True)\npx.imshow(data_frame[non_categorical_columns].corr().round(2))","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:19.051803Z","iopub.execute_input":"2022-01-25T14:03:19.052116Z","iopub.status.idle":"2022-01-25T14:03:19.096855Z","shell.execute_reply.started":"2022-01-25T14:03:19.052076Z","shell.execute_reply":"2022-01-25T14:03:19.095947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\">Nous remarquons qu'aucune des coefficients de corrélation obtenues ne dépasse 50%. Les variables quantitatives ne partagent aucune corrélation entre elles.</p>","metadata":{}},{"cell_type":"markdown","source":"<h2 align=\"center\" class=\"alert alert-success\">Relations entre variables catégorielles et non catégorielles</h2>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\">Nous allons vérifier pour chaque variable quantitative si elle est influencée par une ou plusieurs variable(s) catégorielle(s).</p>","metadata":{}},{"cell_type":"code","source":"def rel_cat_quant(categorical_column):\n    \"\"\"Fonction pour vérifier les relations pouvant exister entre les variables qualitatives\n    et quantitatives. Nous allons utiliser la base de données ne comportant pas de valeurs \n    manquantes.\n    \n    Args:\n        categorical_column(str): Nom de la variable catégorielle\n    \n    Returns:\n        None\n    \"\"\"\n    \n    fig, axs = plt.subplots(2, 2, figsize = (18, 13))\n\n    axs = axs.flat\n\n    for i,column in enumerate(non_categorical_columns):\n\n        sns.histplot(data = data_to_plot, x = column, kde = True, hue = categorical_column, ax = axs[i], palette = \"tab10\")\n\n        axs[i].set_title(f\"Variable {column}\", fontsize = 14)\n\n    fig.delaxes(axs[3])\n\n    fig.tight_layout(pad = 3)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:19.09998Z","iopub.execute_input":"2022-01-25T14:03:19.100934Z","iopub.status.idle":"2022-01-25T14:03:19.110057Z","shell.execute_reply.started":"2022-01-25T14:03:19.100881Z","shell.execute_reply":"2022-01-25T14:03:19.109096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\"><strong>Pour la variable hypertension</strong></p>","metadata":{}},{"cell_type":"code","source":"rel_cat_quant(\"hypertension\")","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:19.111263Z","iopub.execute_input":"2022-01-25T14:03:19.1115Z","iopub.status.idle":"2022-01-25T14:03:21.255825Z","shell.execute_reply.started":"2022-01-25T14:03:19.111471Z","shell.execute_reply":"2022-01-25T14:03:21.254942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\">Nous remarquons une <strong>légère dépendance</strong> entre les variables <strong>hypertension</strong> et <strong>age</strong>.</p>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\"><strong>Pour la variable heart_disease</strong></p>","metadata":{}},{"cell_type":"code","source":"rel_cat_quant(\"heart_disease\")","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:21.257249Z","iopub.execute_input":"2022-01-25T14:03:21.257562Z","iopub.status.idle":"2022-01-25T14:03:23.101542Z","shell.execute_reply.started":"2022-01-25T14:03:21.257518Z","shell.execute_reply":"2022-01-25T14:03:23.100632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\">Nous constatons également une <strong>légère dépendance</strong> entre les variables <strong>heart_disease</strong> et <strong>age</strong>.</p>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\">**Pour la variable gender**</p>","metadata":{}},{"cell_type":"code","source":"rel_cat_quant(\"gender\")","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:23.102689Z","iopub.execute_input":"2022-01-25T14:03:23.102921Z","iopub.status.idle":"2022-01-25T14:03:25.32381Z","shell.execute_reply.started":"2022-01-25T14:03:23.102891Z","shell.execute_reply":"2022-01-25T14:03:25.3231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\">Nous ne remarquons <strong>aucune corrélation</strong> entre la variable <strong>age</strong> et <strong>gender</strong></p>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\"><strong>Pour la variable ever_married</strong></p>","metadata":{}},{"cell_type":"code","source":"rel_cat_quant(\"ever_married\")","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:25.325182Z","iopub.execute_input":"2022-01-25T14:03:25.325488Z","iopub.status.idle":"2022-01-25T14:03:27.108489Z","shell.execute_reply.started":"2022-01-25T14:03:25.325459Z","shell.execute_reply":"2022-01-25T14:03:27.107712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\">La variable <strong>ever_married</strong> est <strong>fortement corrélée</strong> avec les variables <strong>age</strong> et <strong>bmi</strong>.</p>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\"><strong>Pour la variable work_type</strong></p>","metadata":{}},{"cell_type":"code","source":"rel_cat_quant(\"work_type\")","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:27.109994Z","iopub.execute_input":"2022-01-25T14:03:27.110206Z","iopub.status.idle":"2022-01-25T14:03:30.70632Z","shell.execute_reply.started":"2022-01-25T14:03:27.110178Z","shell.execute_reply":"2022-01-25T14:03:30.705338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\">La variable <strong>work_type</strong> également réalise une <strong>forte corrélation</strong> entre les variables <strong>age</strong> et <strong>bmi<strong>. <i>Nous remarquons que la catégorie children de work_type désigne les patients enfants (donc la variable work_type est cohérente pour le reste de l'analyse)</i>.</p>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\"><strong>Pour la variable residence_type</strong></p>","metadata":{}},{"cell_type":"code","source":"rel_cat_quant(\"Residence_type\")","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:30.70757Z","iopub.execute_input":"2022-01-25T14:03:30.707944Z","iopub.status.idle":"2022-01-25T14:03:32.538493Z","shell.execute_reply.started":"2022-01-25T14:03:30.707898Z","shell.execute_reply":"2022-01-25T14:03:32.537864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\">La variable <strong>Residence_type</strong> <strong>n'est pas corrélée</strong> avec la variable <strong>age</strong>.</p>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\"><strong>Pour la variable smoking_status</strong>. Remplacons la catégorie <i>unknown</i> par <i>never smoked</i> pour avoir une meilleure représentation de la variable.</p>","metadata":{}},{"cell_type":"code","source":"data_to_plot[\"smoking_status\"] = data_to_plot[\"smoking_status\"].apply(lambda x: \"never smoked\" if x == \"Unknown\" else x)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:32.539794Z","iopub.execute_input":"2022-01-25T14:03:32.540196Z","iopub.status.idle":"2022-01-25T14:03:32.546282Z","shell.execute_reply.started":"2022-01-25T14:03:32.540154Z","shell.execute_reply":"2022-01-25T14:03:32.545396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_to_plot[\"smoking_status\"].value_counts(normalize=True)*100","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:32.547647Z","iopub.execute_input":"2022-01-25T14:03:32.548057Z","iopub.status.idle":"2022-01-25T14:03:32.56399Z","shell.execute_reply.started":"2022-01-25T14:03:32.548028Z","shell.execute_reply":"2022-01-25T14:03:32.562879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rel_cat_quant(\"smoking_status\")","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:32.565068Z","iopub.execute_input":"2022-01-25T14:03:32.565276Z","iopub.status.idle":"2022-01-25T14:03:34.833887Z","shell.execute_reply.started":"2022-01-25T14:03:32.565249Z","shell.execute_reply":"2022-01-25T14:03:34.833019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\">La variable <strong>smoking_status</strong> est <strong>fortement corrélée</strong> avec la variable <strong>age</strong>.</p>","metadata":{}},{"cell_type":"markdown","source":"<h2 align=\"center\" class=\"alert alert-success\">Identification des valeurs aberrantes</h2>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\">Tracons les boxplots des variables catégorielles en les séparant par classe de patients (atteints d'AVC ou pas).</p>","metadata":{}},{"cell_type":"code","source":"fig, axs = plt.subplots(2, 2, figsize = (18, 14))\n\naxs = axs.flat\n\nfor i,column in enumerate(non_categorical_columns):\n\n    sns.boxplot(data = data_to_plot, x = \"stroke\", y = column, hue = \"stroke\", ax = axs[i], palette = \"tab10\")\n\n    axs[i].set_title(f\"Variable {column}\", fontsize = 14)\n\nfig.delaxes(axs[3])\n\nfig.tight_layout(pad = 3)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:34.835083Z","iopub.execute_input":"2022-01-25T14:03:34.8353Z","iopub.status.idle":"2022-01-25T14:03:35.542165Z","shell.execute_reply.started":"2022-01-25T14:03:34.835273Z","shell.execute_reply":"2022-01-25T14:03:35.541279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\">Nous constatons que tous les trois variables comportent des valeurs aberrantes. Surtout du coté de la classe *test negatif* de la variable stroke (pour les variables bmi et avg_glucose_level).</p>","metadata":{}},{"cell_type":"markdown","source":"<h2 align=\"center\" class=\"alert alert-success\">Test d'hypothéses</h2>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\">Vérifions si certaines variables quantitatives influencent le fait qu'un patient soit atteint d'AVC ou pas avec un test de student.</p>","metadata":{}},{"cell_type":"code","source":"# Définition de la fonction pour effectuer des tests\ndef student_test(dataframe1: pd.DataFrame, dataframe2: pd.DataFrame, colonnes: list, alpha: float):\n    \"\"\"Cette fonction permet d'effectuer un test de student.\n    \n    Args:\n        dataframe1(pandas.DataFrame): Les données de la première classe.\n        dataframe2(pandas.DataFrame): Les données de la deuxième classe.\n        colonne(list): Les noms des colonnes sur les quelles on va réaliser le test.\n        alpha(float): Le taux d'erreur alpha de l'hypothèse nulle.\n    \n    Returns:\n        None\n    \"\"\"\n    \n    # Choix d'un échantillon pour le dataframe qui a la plus grande taille\n    if dataframe1.shape[0] <= dataframe2.shape[0]:\n        dataframe2 = dataframe2.sample(dataframe1.shape[0])\n    else:\n        dataframe1 = dataframe1.sample(dataframe2.shape[0])\n        \n    for colonne in colonnes:\n        stat, p = ttest_ind(dataframe1[colonne], dataframe2[colonne])\n        if  p < alpha:\n            print(f\"{colonne:-<30} : H0 rejetée\")\n        else:\n            print(f\"{colonne:-<30} : H0 non rejetée\")","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:35.543552Z","iopub.execute_input":"2022-01-25T14:03:35.544053Z","iopub.status.idle":"2022-01-25T14:03:35.550634Z","shell.execute_reply.started":"2022-01-25T14:03:35.54401Z","shell.execute_reply":"2022-01-25T14:03:35.549816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\">Nous devons d'abord séparer le dataframe entre les catégories <i>test positif</i> et <i>test negatif</i></p>","metadata":{}},{"cell_type":"code","source":"df_positif, df_negatif = data_frame[data_frame[\"stroke\"] == 1], data_frame[data_frame[\"stroke\"] == 0]","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:35.551882Z","iopub.execute_input":"2022-01-25T14:03:35.552203Z","iopub.status.idle":"2022-01-25T14:03:35.571992Z","shell.execute_reply.started":"2022-01-25T14:03:35.552169Z","shell.execute_reply":"2022-01-25T14:03:35.570977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Effectuons le test\nstudent_test(df_positif, df_negatif, non_categorical_columns, 0.02)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:35.573149Z","iopub.execute_input":"2022-01-25T14:03:35.573814Z","iopub.status.idle":"2022-01-25T14:03:35.590175Z","shell.execute_reply.started":"2022-01-25T14:03:35.573777Z","shell.execute_reply":"2022-01-25T14:03:35.589219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\">Selon le test <strong>seule la variable bmi n'influence pas le fait qu'un patient soit malade ou pas</strong>.</p>","metadata":{}},{"cell_type":"markdown","source":"<h1 align=\"center\" class=\"alert alert-info\">Phase de Prétraitement des données</h1>","metadata":{}},{"cell_type":"markdown","source":"<h2 align=\"center\" class=\"alert alert-success\">Étapes du prétraitement</h2>\n<div style =\"font-family:'Times New Roman'\" align=\"justify\">\n<p>Nous allons effectuer plusieurs traitements sur les données et vérifier le score obtenu après entraînement d'un modèle d'arbre de décision (il ne s'agit pas du modèle final). Nous considérons que l'arbre de décision est le modèle de classification le plus facile à interpréter c'est pourquoi il est nécessaire de l'utiliser durant la phase de prétraitement.</p>\n<ul>\n    <li><strong>Suppression de variables</strong> : Nous diminuons considérablement le risque de sur-entraînement de nos modèles en supprimant les variables inutiles. Les variables fortement corrélées entre elles fournissent les mêmes informations au modèle. Ce surplus d'informations peut-être corrigé avec la suppression de certaines variables.</li>\n    <li><strong>Suppression des données aberrantes</strong> : Toutes les valeurs de la variable avg_glucose_level supérieures à environ 169 mg/dL, soit les valeurs désignant les patients qui ont un taux anormal de glucose dans le sang, sont supprimées. Nous obtenons ainsi une distribution à peu près normale pour la variable avg_glucose_level. La distribution de la variable age reste à peu près la même. Après la suppression des valeurs aberrantes, la taille de l'échantillon est de <strong>4483</strong>.</li>\n    <li><strong>Séparation des données</strong> en données d'entraînement et de test : Les données d'entraînement vont contenir <strong>3586</strong> observations et les données de test, <strong>897</strong> observations.</li>\n    <li><strong>Encodage des données qualitatives</strong> : </li>\n    <li><strong>Entraînement du modèle de test</strong> : </li>\n    <li><strong>Evaluation du modèle</strong> : En supprimant uniquement les variables bmi, work_type, ever_married, smoking_status et id on obtient une sensibilité de <strong>96%</strong> pour la classe <i>test negatif</i> et seulement <strong>20%</strong> pour la class <i>test positif</i>.</li>\n    <li><strong>Selection de variables</strong> : Les variables gender, hypertension, heart_disease et Residence_type sont celles qui doivent être supprimées. Ces variables sont les moins explicatives du lot de variables qui ont servies à la précedente entraînement. Les variables age et avg_glucose_level sont à l'inverse les meilleures variables.</li>\n    <li><strong>Entraînement et évaluation du modèle de test</strong> avec les variables choisies : Nous obtenons une sensibilité de <strong>96%</strong> pour la classe <i>test negatif</i> et <strong>29%</strong> (soit une amélioration de 9%) pour la classe <i>test positif</i>.</li>\n    <li><strong>Conclusion</strong> : Nous obtenons un bon score pour la classe <i>test negatif</i> mais pas pour la classe <i>test positif</i> qui reste très faible. Nous supposons que les données utilisées n'expliquent pas bien le phénomène *attraper un AVC*.</li>\n    <li><strong>Recommandations</strong> : Il est crucial de recueillir plus de données et d'augmenter le nombre de variables pertinentes nécessaires à l'analyse et à l'entraînement d'un modèle de détection d'AVC. La complétude dans la collecte n'a pas été totalement respectée.</li>\n</ul>\n</div>\n\n","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\">Conception d'une classe comprenant les différentes étapes du traitement.</p>","metadata":{}},{"cell_type":"code","source":"class Traitement:\n    \"\"\"Cette classe va nous permettre d'effectuer des traitements sur les données.\n    \n    Attributes:\n        dataframe(pandas.DataFrame): Les données avant tout traitement.\n        cible(str): Le nom de la variable cible\n    \"\"\"\n    \n    def __init__(self, dataframe, cible):\n        \"\"\"Initialisation des attributs\n        \"\"\"\n        if cible in dataframe.columns:\n            self.dataframe = dataframe.copy()\n            self.cible = cible\n        else:\n            raise ValueError(\"Le nom de la cible ne correspond à aucune colonne\")\n    \n    def colonne_existe(self, colonne):\n        \"\"\"Fonction permettant de vérifier si une colonne existe.\n        \"\"\"\n        return True if colonne in self.dataframe.columns else False\n    \n    def supprimer_colonnes(self, colonnes):\n        \"\"\"Cette fonction permet de supprimer des colonnes.\n        \"\"\"\n        for colonne in colonnes:\n            if self.colonne_existe(colonne):\n                self.dataframe.drop(colonne, axis = 1, inplace = True)\n            else:\n                raise ValueError(f\"La colonne {colonne} n'existe pas.\")\n    \n    def modification_categorie(self, colonne, categorie_a_modif, categorie_de_modif):\n        \"\"\"Cette fonction permet de modifier une catégorie par une autre catégorie au sein\n        d'une variable catégorielle.\n        \"\"\"\n        modif = lambda x: categorie_de_modif if x == categorie_a_modif else x\n        if self.colonne_existe(colonne):\n            if self.dataframe[colonne].dtype == \"category\":\n                self.dataframe[colonne] = self.dataframe[colonne].apply(modif)\n                self.dataframe[colonne] = self.dataframe[colonne].astype('category')\n            else:\n                raise TypeError(f\"La colonne {colonne} n'est pas une colonne catégorielle.\")\n        else:\n            raise ValueError(f\"La colonne {colonne} n'existe pas.\")\n    \n    def supprimer_aberrantes(self, colonne):\n        \"\"\"Cette fonction permet de remplacer les valeurs aberrantes par la médiane \n        des données suivant une colonne à préciser\n        \"\"\"\n        if self.colonne_existe(colonne):\n            quantile_1 = self.dataframe[colonne].quantile(0.25)\n            quantile_2 = self.dataframe[colonne].quantile(0.75)\n            mediane = self.dataframe[colonne].median()\n            inter_quantile = quantile_2 - quantile_1\n            limite_bas = quantile_1 - 1.5 * inter_quantile\n            limite_haut = quantile_2 + 1.5 * inter_quantile\n#             remplacer_aberrante = lambda x : mediane if (x < limite_bas or x > limite_haut) else x\n#             self.dataframe[colonne] = self.dataframe[colonne].apply(remplacer_aberrante)\n            self.dataframe = self.dataframe[(self.dataframe[colonne] > limite_bas) & (self.dataframe[colonne] < limite_haut)]\n        else:\n            raise ValueError(f\"La colonne {colonne} n'existe pas.\")\n    \n    def separer_donnees(self, dataframe):\n        \"\"\"Cette fonction permet de séparer les données d'entraînement des données de test\n        \"\"\"\n        y = dataframe[self.cible]\n        \n        X = dataframe.drop(self.cible, axis = 1)\n\n#         from sklearn.preprocessing import PolynomialFeatures\n#         polynomial_converter = PolynomialFeatures(degree=2, include_bias=False)\n#         polynomial_converter.fit(X)\n#         X = polynomial_converter.transform(X)\n        \n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 4)\n\n        from sklearn.model_selection import StratifiedKFold\n        sk = StratifiedKFold(n_splits=2, random_state=None, shuffle=False)\n        \n        for train, test in sk.split(X, y):\n            X_train , X_test = X.iloc[train], X.iloc[test]\n            y_train , y_test = y.iloc[train], y.iloc[test]\n        \n        return X_train, X_test, y_train, y_test\n    \n    def encodage(self):\n        \"\"\"Cette fonction permet d'encoder les valeurs qualitatives\n        \"\"\"\n        dataframe = self.dataframe.copy()\n        for colonne in dataframe.select_dtypes(\"category\").columns:\n            dataframe[colonne] = self.dataframe[colonne].cat.codes\n        return dataframe\n    \n    def selection_variables(self, modele, X_train, y_train):\n        \"\"\"Cette fonction permet de sélectionner les variables qui apportent le plus d'information\n        au modèle donné en paramètre.\n        \"\"\"\n        from sklearn.feature_selection import SelectFromModel\n        selector = SelectFromModel(modele)\n        selector.fit(X_train, y_train)\n        print(f\"Colonnes choisies : \\n\", X_train.columns[selector.get_support()])\n        return selector\n    \n    def premier_entrainement(self, X_train, y_train):\n        \"\"\"Cette fonction permet d'entraîner le premier modèle pour vérifier si le traitement effectué\n        est bon.\n        \"\"\"\n        from sklearn.tree import DecisionTreeClassifier\n        \n        modele = DecisionTreeClassifier(random_state = 4)\n        \n        modele.fit(X_train, y_train)\n        \n        return modele\n    \n    def evaluation(self, modele, nom_modele, X_train, X_test, y_train, y_test, plot_roc = False):\n        \"\"\"Cette fonction permet d'évaluer un modèle\n        \"\"\"\n        from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n        from sklearn.model_selection import learning_curve\n        import numpy as np\n        \n        y_pred = modele.predict(X_test)\n        \n        print(f\"La precision du modèle : {accuracy_score(y_test, y_pred)}\")\n        print(f\"Matrice de confusion : \\n{confusion_matrix(y_test, y_pred)}\")\n        print(f\"Rapport de classification : \\n{classification_report(y_test, y_pred)}\")\n        \n        from sklearn.metrics import mean_squared_error\n        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n        print(f'RMSE : {rmse}')\n        \n        N, train_score, test_score = learning_curve(modele, X_train, y_train, cv = 5, train_sizes = np.linspace(0.1, 1, 10))\n        \n        fig, axs = plt.subplots(1, 2, figsize = (17, 8))  \n        \n        axs[0].plot(N, train_score.mean(axis = 1), label = \"score_entrainement\")\n        axs[0].plot(N, test_score.mean(axis = 1), label = \"score_test\")\n        axs[0].set_title(f\"Evaluation {nom_modele}\")\n        axs[0].set_xlabel(f\"Tailles\")\n        axs[0].set_ylabel(f\"Scores\")\n        axs[0].legend()\n        \n        plot_roc_curve(modele, X_test, y_test, ax = axs[1])\n        axs[1].set_title(f\"Courbe ROC {nom_modele}\")\n         \n        fig.tight_layout(w_pad = 3)\n        ","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:35.591727Z","iopub.execute_input":"2022-01-25T14:03:35.592054Z","iopub.status.idle":"2022-01-25T14:03:35.616515Z","shell.execute_reply.started":"2022-01-25T14:03:35.592011Z","shell.execute_reply":"2022-01-25T14:03:35.615738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Création d'une instance de la classe Traitement \ntraitement = Traitement(data_frame, \"stroke\")","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:35.617847Z","iopub.execute_input":"2022-01-25T14:03:35.620127Z","iopub.status.idle":"2022-01-25T14:03:35.635018Z","shell.execute_reply.started":"2022-01-25T14:03:35.620085Z","shell.execute_reply":"2022-01-25T14:03:35.634089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 align=\"center\" class=\"alert alert-success\">suppression de variables</h2>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\">Supprimons les colonnes bmi, work_type, ever_married, smoking_status et id.</p>","metadata":{}},{"cell_type":"code","source":"traitement.supprimer_colonnes(['bmi', 'work_type', 'ever_married', 'smoking_status', 'id'])    ","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:35.63635Z","iopub.execute_input":"2022-01-25T14:03:35.636868Z","iopub.status.idle":"2022-01-25T14:03:35.65401Z","shell.execute_reply.started":"2022-01-25T14:03:35.636822Z","shell.execute_reply":"2022-01-25T14:03:35.6533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Vérifions quelles sont les variables restantes \ntraitement.dataframe.columns","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:35.655148Z","iopub.execute_input":"2022-01-25T14:03:35.655509Z","iopub.status.idle":"2022-01-25T14:03:35.66866Z","shell.execute_reply.started":"2022-01-25T14:03:35.65547Z","shell.execute_reply":"2022-01-25T14:03:35.667997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 align=\"center\" class=\"alert alert-success\">Suppression des données aberrantes</h2>","metadata":{}},{"cell_type":"code","source":"traitement.supprimer_aberrantes(\"age\")\ntraitement.supprimer_aberrantes(\"avg_glucose_level\")","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:35.669795Z","iopub.execute_input":"2022-01-25T14:03:35.670132Z","iopub.status.idle":"2022-01-25T14:03:35.688204Z","shell.execute_reply.started":"2022-01-25T14:03:35.670104Z","shell.execute_reply":"2022-01-25T14:03:35.687244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\">Traçons les distributions des deux variables quantitatives.</p>","metadata":{}},{"cell_type":"code","source":"fig, axs = plt.subplots(1, 2, figsize = (17, 6))\n\naxs = axs.flat\n\nfor i, colonne in enumerate([\"age\", \"avg_glucose_level\"]):\n    fig.tight_layout(w_pad = 3, pad = 1.2)\n    sns.histplot(data = traitement.dataframe, x = colonne, hue = \"stroke\", kde = True, ax = axs[i], palette = \"tab10\")\n    axs[i].set_title(f\"distribution de la colonne {colonne}\")","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:35.689696Z","iopub.execute_input":"2022-01-25T14:03:35.690187Z","iopub.status.idle":"2022-01-25T14:03:36.689396Z","shell.execute_reply.started":"2022-01-25T14:03:35.690143Z","shell.execute_reply":"2022-01-25T14:03:36.688577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Vérifions combien de données il nous reste\ntraitement.dataframe.shape[0]","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:36.690888Z","iopub.execute_input":"2022-01-25T14:03:36.691354Z","iopub.status.idle":"2022-01-25T14:03:36.697378Z","shell.execute_reply.started":"2022-01-25T14:03:36.691311Z","shell.execute_reply":"2022-01-25T14:03:36.696582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 align=\"center\" class=\"alert alert-success\">Encodage des données qualitatives</h2>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\">Nous devons récupérer dans une nouvelle variable le nouveau dataframe dont les données qualitatives seront encodées.</p>","metadata":{}},{"cell_type":"code","source":"new_data_frame = traitement.encodage()","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:36.698843Z","iopub.execute_input":"2022-01-25T14:03:36.699307Z","iopub.status.idle":"2022-01-25T14:03:36.714878Z","shell.execute_reply.started":"2022-01-25T14:03:36.699265Z","shell.execute_reply":"2022-01-25T14:03:36.713881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 align=\"center\" class=\"alert alert-success\">Séparation des données</h2>","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = traitement.separer_donnees(new_data_frame)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:36.716076Z","iopub.execute_input":"2022-01-25T14:03:36.716703Z","iopub.status.idle":"2022-01-25T14:03:36.727464Z","shell.execute_reply.started":"2022-01-25T14:03:36.716636Z","shell.execute_reply":"2022-01-25T14:03:36.726725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Verifions les tailles des variables explicatives\nX_train.shape, X_test.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:36.728609Z","iopub.execute_input":"2022-01-25T14:03:36.729006Z","iopub.status.idle":"2022-01-25T14:03:36.73642Z","shell.execute_reply.started":"2022-01-25T14:03:36.728975Z","shell.execute_reply":"2022-01-25T14:03:36.735644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 align=\"center\" class=\"alert alert-success\">Premier entraînement avec un arbre de décision</h2>","metadata":{}},{"cell_type":"code","source":"modele = traitement.premier_entrainement(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:36.737498Z","iopub.execute_input":"2022-01-25T14:03:36.737877Z","iopub.status.idle":"2022-01-25T14:03:36.754077Z","shell.execute_reply.started":"2022-01-25T14:03:36.737836Z","shell.execute_reply":"2022-01-25T14:03:36.753435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 align=\"center\" class=\"alert alert-success\">Evaluation du modèle</h2>","metadata":{}},{"cell_type":"code","source":"sns.set_theme(style = \"darkgrid\")","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:36.75539Z","iopub.execute_input":"2022-01-25T14:03:36.755785Z","iopub.status.idle":"2022-01-25T14:03:36.762368Z","shell.execute_reply.started":"2022-01-25T14:03:36.755746Z","shell.execute_reply":"2022-01-25T14:03:36.76169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"traitement.evaluation(modele, \"Arbre de décision\", X_train, X_test, y_train, y_test)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:36.76332Z","iopub.execute_input":"2022-01-25T14:03:36.763844Z","iopub.status.idle":"2022-01-25T14:03:37.766724Z","shell.execute_reply.started":"2022-01-25T14:03:36.763809Z","shell.execute_reply":"2022-01-25T14:03:37.766077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 align=\"center\" class=\"alert alert-success\">Sélection de variables</h2>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\">Vérifions quelles sont les variables qui apportent le plus d'information au modèle d'arbre de décision.</p>","metadata":{}},{"cell_type":"code","source":"selector = traitement.selection_variables(tree.DecisionTreeClassifier(random_state = 4), X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:37.767954Z","iopub.execute_input":"2022-01-25T14:03:37.768273Z","iopub.status.idle":"2022-01-25T14:03:37.780522Z","shell.execute_reply.started":"2022-01-25T14:03:37.768244Z","shell.execute_reply":"2022-01-25T14:03:37.779727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\">Les variables qui n'apportent pas d'information au modèle sont les variables gender, hypertension, heart_disease et Residence_type qui vont être supprimées des données d'entraînement et de test.</p>","metadata":{}},{"cell_type":"code","source":"colonnes_choisies = X_train.columns[selector.get_support()]","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:37.781752Z","iopub.execute_input":"2022-01-25T14:03:37.781946Z","iopub.status.idle":"2022-01-25T14:03:37.78563Z","shell.execute_reply.started":"2022-01-25T14:03:37.781921Z","shell.execute_reply":"2022-01-25T14:03:37.785095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test = X_train[colonnes_choisies], X_test[colonnes_choisies]","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:37.786739Z","iopub.execute_input":"2022-01-25T14:03:37.787109Z","iopub.status.idle":"2022-01-25T14:03:37.796726Z","shell.execute_reply.started":"2022-01-25T14:03:37.787081Z","shell.execute_reply":"2022-01-25T14:03:37.796087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 align=\"center\" class=\"alert alert-success\">Nouveau entraînement du modèle avec les variables choisies</h2>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\"><strong>Entraînement</strong></p>","metadata":{}},{"cell_type":"code","source":"modele = traitement.premier_entrainement(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:37.798141Z","iopub.execute_input":"2022-01-25T14:03:37.798579Z","iopub.status.idle":"2022-01-25T14:03:37.812695Z","shell.execute_reply.started":"2022-01-25T14:03:37.798549Z","shell.execute_reply":"2022-01-25T14:03:37.811901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\"><strong>Evaluation</strong></p>","metadata":{}},{"cell_type":"code","source":"traitement.evaluation(modele, \"Arbre de décision\", X_train, X_test, y_train, y_test)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:37.814032Z","iopub.execute_input":"2022-01-25T14:03:37.814438Z","iopub.status.idle":"2022-01-25T14:03:38.773777Z","shell.execute_reply.started":"2022-01-25T14:03:37.814408Z","shell.execute_reply":"2022-01-25T14:03:38.772925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\">Nous notons une amélioration du score.</p>","metadata":{}},{"cell_type":"markdown","source":"<h1 align=\"center\" class=\"alert alert-info\">Phase de modélisation</h1>","metadata":{}},{"cell_type":"markdown","source":"<h2 align=\"center\" class=\"alert alert-success\">Préambule</h2>\n<p style=\"font-family:'Times New Roman'\">On devra entraîner un certain nombre de modèles et sélectionner celui qui donnera le meilleur score et qui ne sera ni trop complexe (score élevé sur les données d'entraînement et faible sur les données de test) et ni trop simple (score faible sur les données d'entraînement et de test). \n    Le modèle final sera choisi parmi les suivantes : <strong>RandomForestClassifier</strong>, <strong>AdaBoostClassifier</strong>, <strong>SVC</strong>, <strong>KNeighborsClassifier</strong> et <strong>LogisticRegression</strong>.</p>\n","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\">Concevons une classe capable d'entraîner plusieurs modèles à partir des données qui lui seront fournies et qui héritera des méthodes de la classe de prétraitement.</p>","metadata":{}},{"cell_type":"code","source":"class SelectionModele(Traitement):\n    \"\"\"Cette classe permet d'effectuer plusieurs entraînement avec un certain nombre de modèles et hérite\n    des méthodes de la classe Traitement\n    Attributes:\n        None    \n    \"\"\"\n    \n    def __init__(self):\n        pass\n    \n    def multiple_entrainements(self, X_train, X_test, y_train, y_test):\n        \"\"\"\n        \"\"\"\n        from sklearn.compose import make_column_transformer, make_column_selector\n        from sklearn.pipeline import make_pipeline\n        from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n        from sklearn.preprocessing import OneHotEncoder\n        from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n        from sklearn.neighbors import KNeighborsClassifier\n        from sklearn.linear_model import LogisticRegression\n        from sklearn.svm import SVC\n        \n        \n        variables_numeriques = make_column_selector(dtype_include=np.number)\n        \n        pipeline_numerique = make_pipeline(StandardScaler(), PolynomialFeatures())\n        \n        preprocesseur = make_column_transformer((pipeline_numerique, variables_numeriques))\n        \n        Forest = make_pipeline(preprocesseur, RandomForestClassifier(random_state = 4))\n        Adaboost = make_pipeline(preprocesseur, AdaBoostClassifier(random_state = 4))\n        Svc = make_pipeline(preprocesseur, SVC(random_state = 4))\n        KNeighbors = make_pipeline(preprocesseur, KNeighborsClassifier())\n        Logistic = make_pipeline(preprocesseur, LogisticRegression(random_state = 4))\n        \n        modeles_dict = {\"Forêt aléatoire\" : Forest,\n                       \"Adaboost\" : Adaboost,\n                       \"SVC\" : Svc,\n                       \"KNN\" : KNeighbors,\n                       \"Logistic\" : Logistic\n                      }\n        \n        for nom, modele in modeles_dict.items():\n            print(f\"{'-'*15}\\nPour le modèle {nom} :\")\n            modele.fit(X_train, y_train)\n            self.evaluation(modele, nom, X_train, X_test, y_train, y_test, True)\n            yield nom, modele\n        \n    def courbe_sensibilite_precision(self, modele, X_test, y_test):\n        \"\"\"Une fonction qui permet de tracer la courbe de Precision-Recall pour le choix d'un seuil.\n        Args:\n            modele (pipeline): Le modèle choisi\n            X_test (pandas.DataFrame): Les caractéristiques de test\n            y_test (pandas.DataFrame): Les données test de la cible\n        \n        Returns:\n            None\n        \"\"\"\n        from sklearn.metrics import precision_recall_curve\n        \n        precision, sensibilite, seuil = precision_recall_curve(y_test, modele.decision_function(X_test))\n        \n        plt.plot(seuil, precision[:-1], label = 'precision')\n        plt.plot(seuil, sensibilite[:-1], label = 'sensibilité')\n        plt.legend()","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:38.775122Z","iopub.execute_input":"2022-01-25T14:03:38.775491Z","iopub.status.idle":"2022-01-25T14:03:38.78662Z","shell.execute_reply.started":"2022-01-25T14:03:38.775455Z","shell.execute_reply":"2022-01-25T14:03:38.785957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# instenciation de la classe\nselection_modele = SelectionModele()","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:38.787871Z","iopub.execute_input":"2022-01-25T14:03:38.788601Z","iopub.status.idle":"2022-01-25T14:03:38.803492Z","shell.execute_reply.started":"2022-01-25T14:03:38.788552Z","shell.execute_reply":"2022-01-25T14:03:38.802617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 align=\"center\" class=\"alert alert-success\">Sélection de modèle</h2>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\">Récupération d'un générateur qui nous permettra d'effectuer les entraînements et évaluation des modèles.</p>","metadata":{}},{"cell_type":"code","source":"# initialisation du générateur\ngenerateur_modeles = selection_modele.multiple_entrainements(X_train, X_test, y_train, y_test)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:38.804825Z","iopub.execute_input":"2022-01-25T14:03:38.805061Z","iopub.status.idle":"2022-01-25T14:03:38.815936Z","shell.execute_reply.started":"2022-01-25T14:03:38.805034Z","shell.execute_reply":"2022-01-25T14:03:38.815133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3 align=\"center\" class=\"alert alert-warning\">Random Forest</h3>","metadata":{}},{"cell_type":"code","source":"nom, modele = next(generateur_modeles)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:38.817281Z","iopub.execute_input":"2022-01-25T14:03:38.817498Z","iopub.status.idle":"2022-01-25T14:03:52.214661Z","shell.execute_reply.started":"2022-01-25T14:03:38.817473Z","shell.execute_reply":"2022-01-25T14:03:52.213153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3 align=\"center\" class=\"alert alert-warning\">Adaboost</h3>","metadata":{}},{"cell_type":"code","source":"nom, modele = next(generateur_modeles)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:52.216116Z","iopub.execute_input":"2022-01-25T14:03:52.216436Z","iopub.status.idle":"2022-01-25T14:03:59.63455Z","shell.execute_reply.started":"2022-01-25T14:03:52.216396Z","shell.execute_reply":"2022-01-25T14:03:59.63373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3 align=\"center\" class=\"alert alert-warning\">SVC</h3>","metadata":{}},{"cell_type":"code","source":"nom, modele = next(generateur_modeles)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:03:59.635888Z","iopub.execute_input":"2022-01-25T14:03:59.636341Z","iopub.status.idle":"2022-01-25T14:04:02.028059Z","shell.execute_reply.started":"2022-01-25T14:03:59.636301Z","shell.execute_reply":"2022-01-25T14:04:02.027102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3 align=\"center\" class=\"alert alert-warning\">KNN</h3>","metadata":{}},{"cell_type":"code","source":"nom, modele = next(generateur_modeles)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:04:02.029847Z","iopub.execute_input":"2022-01-25T14:04:02.030214Z","iopub.status.idle":"2022-01-25T14:04:05.631592Z","shell.execute_reply.started":"2022-01-25T14:04:02.030165Z","shell.execute_reply":"2022-01-25T14:04:05.630741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3 align=\"center\" class=\"alert alert-warning\">LOGISTIC</h3>","metadata":{}},{"cell_type":"code","source":"nom, modele = next(generateur_modeles)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:04:05.633106Z","iopub.execute_input":"2022-01-25T14:04:05.633754Z","iopub.status.idle":"2022-01-25T14:04:07.837212Z","shell.execute_reply.started":"2022-01-25T14:04:05.633707Z","shell.execute_reply":"2022-01-25T14:04:07.836074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\">Le meilleur modèle est donc la <strong>régression logistique</strong> avec une aire sous la courbe de <strong>84%</strong>.</p>","metadata":{}},{"cell_type":"markdown","source":"<h2 align=\"center\" class=\"alert alert-success\">Description du modèle choisi</h2>","metadata":{}},{"cell_type":"markdown","source":"<h3 align=\"center\" class=\"alert alert-warning\">C'est quoi la régression logistique ?</h3>","metadata":{}},{"cell_type":"markdown","source":"<div align=\"justify\" style = \"font-family:'Times New Roman'\">\n<p>La régression logistique est une méthode qui permet de modéliser des variables binomiales (typiquement binaires), multinomiales (variables qualitatives à plus de deux modalités) ou ordinales (variables qualitatives dont les modalités sont ordonnées). Elle est très utilisée dans le domaine médical (guérison ou non d'un patient), en sociologie, en épidémiologie, en marketing quantitatif (achat ou non de produits ou services suite à une action) et en finance pour la modélisation de risques (scoring).</p>\n<p>Le principe du modèle de la régression logistique est d'expliquer la survenance ou non d'un événement (la variable cible que nous noterons y) par le niveau de variables explicatives (notées X). Dans notre exemple, on cherche à prédire la sortie de la variable y (patient atteint d'AVC ou pas) en fonction des données relevées sur les patients.</p>\n</div>","metadata":{}},{"cell_type":"markdown","source":"<h3 align=\"center\" class=\"alert alert-warning\">Comment fonctionne la régression logistique ?</h3>","metadata":{}},{"cell_type":"markdown","source":"<div align=\"justify\" style = \"font-family:'Times New Roman'\">\n<p>La régression logistique et la régression linéaire appartiennent à la même famille des modèles GLM (<span style = \"color:blue\"><i>Generalized Linear Models</i></span>) : dans les deux cas, on relie un événement à une combinaison linéaire de variables explicatives.</p>\n<p>Dans le cas de la régression linéaire ordinaire, la variable dédendante Y suit une loi normale $N(\\mu, \\sigma)$ où $\\mu$ est une fonction linéaire des variables explicatives. Pour la régression logistique binomiale, la variable dépendante, aussi appelée variable réponse, suit une loi de Bernoulli de paramètre p (p étant la probabilité pour que l'événement se produise), lorsque l'expérience est répétée une fois, ou une loi Binomiale(n, p) si l'expérience est répétée n fois (par exemple la même dose est essayée sur n patients). Dans le cas de la régression logistique, le paramètre de probabilité p est une fonction combinaison linéaire des variables explicatives X.\n<p>Le cas <span style = \"color:blue\"><i>\"binaire\"</i></span> est le cas où la variable réponse peut prendre 2 valeurs (correspondant à un tirage de Bernoulli), et le cas <span style = \"color:blue\"><i>\"somme de binaires\"</i></span> le cas où la variable réponse est le comptage du nombre de fois où l'événement d'intérêt s'est produit.\n<p>Les fonctions les plus couramment utilisées pour relier la probabilité p aux variables explicatives sont la fonction logistique (on parle alors de modèles <span style = \"color:darkviolet\"><i>Logit</i></span>) et la fonction de répartition de la loi normale standard (on parle alors de modèle <span style = \"color:darkcyan\"><i>Probit</i></span>). Ces deux fonctions sont parfaitement symétriques et sigmoïdes (La courbe en S représentée par la fonction $f_\\lambda(x) = f(\\lambda x) = \\frac{1}{1+e^{-\\lambda x}}$). La fonction sigmoide à la particularité d'être toujours comprise entre 0 et 1. Ainsi pour un seuil fixé entre 0 et 1 (la plupart du temps un seuil de 0.5) si le résultat de la fonction sigmoide, suivant les valeurs en entrées, est supérieur ou égale au seuil, alors on considère que l'individu est de classe 1 et sinon on considère qu'il est de classe 0. Dans le cas du dépistage de cancer du poumon on considérera ainsi que si les données d'un patient conduisent à la classe 1 alors il atteint de cancer et sinon il n'est pas atteint. A chaque résultat on attribue une probabilité qui indique son taux de certitude.\n</div>\n","metadata":{}},{"cell_type":"markdown","source":"<h3 align=\"center\" class=\"alert alert-warning\">Les paramètres du modèle</h3>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\">Affichage des paramètres du modèle.</p>","metadata":{}},{"cell_type":"code","source":"modele.get_params()","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:04:07.83897Z","iopub.execute_input":"2022-01-25T14:04:07.83942Z","iopub.status.idle":"2022-01-25T14:04:07.867251Z","shell.execute_reply.started":"2022-01-25T14:04:07.839386Z","shell.execute_reply":"2022-01-25T14:04:07.866249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div align=\"justify\" style = \"font-family:'Times New Roman'\">\n    <ul>\n        <li><strong>penalty (pénalité)</strong> : Ce paramètre est utilisé pour spécifier la norme (L1 ou L2) utilisée dans la pénalisation (régularisation). Il peut prendre les valeurs : 'L1', 'L2', 'elasticnet' ou none (aucun).</li>\n        <li><strong>dual (double)</strong> : Il est utilisé pour la formulation double ou primale. La formulation double n’est mise en œuvre que pour la pénalité L2. Il prend des valeurs booléennes. </li>\n        <li><strong>tol (tolérance)</strong> : Il représente la tolérance pour les critères d’arrêt.</li>\n        <li><strong>C</strong> : Il représente l’inverse de la force de régularisation. Il doit toujours être un décimale positif.</li>\n        <li><strong>fit_intercept</strong> : Ce paramètre spécifie si une constante (biais ou interception) doit être ajoutée à la fonction de décision. Il prend des valeurs booléennes.</li>\n        <li><strong>intercept_scaling</strong> : Ce paramètre est utile lorsque le solveur 'liblinear' est utilisé ou que 'fit_intercept' est défini sur vraie. Il prend des valeurs décimales.</li>\n        <li><strong>class_weight</strong> : Il représente les poids associés aux classes. Si nous utilisons l’option par défaut ('none' qui veut dire aucun), cela signifie que toutes les classes sont censées avoir un poids égale à 1. D’autre part, si vous choisissez la valeur 'équilibré', il utilisera les valeurs de y pour ajuster automatiquement les poids.</li>\n        <li><strong>random_state</strong> : Ce paramètre représente la graine du nombre pseudo aléatoire généré qui est utilisé lors du brassage des données. Voici les options -\n            <ul>\n                <li><strong>int (entier)</strong> : dans ce cas, random_state est la graine utilisée par le générateur de nombres aléatoires.</li>\n                <li><strong>'Instance RandomState'</strong> : dans ce cas, random_state est le générateur de nombres aléatoires.</li>\n                <li><strong>Aucun</strong> : dans ce cas, le générateur de nombres aléatoires est l’instance RandonState utilisée par np.random.</li>\n            </ul>\n        </li>\n        <li><strong>solver (solveur)</strong> : Ce paramètre représente l’algorithme à utiliser dans le problème d’optimisation. Voici les propriétés des options sous ce paramètre -\n            <ul>\n                <li><strong>liblinear</strong> : C’est un bon choix pour les petits ensembles de données. Il gère également la pénalité L1. Pour les problèmes multiclasses, il est limité aux schémas à un contre repos.</li>\n                <li><strong>newton-cg</strong> : Il ne gère que la pénalité L2.</li>\n                <li><strong>lbfgs</strong> : Pour les problèmes multiclasses, il gère la perte multinomiale. Il ne gère également que la pénalité L2.</li>\n                <li><strong>saga</strong> : C’est un bon choix pour les grands ensembles de données. Pour les problèmes multiclasses, il gère également la perte multinomiale. En plus de la pénalité L1, il prend également en charge la pénalité « elasticnet ».</li>\n                <li><strong>sag</strong> : Il est également utilisé pour les grands ensembles de données. Pour les problèmes multiclasses, il gère également la perte multinomiale.</li>\n            </ul>\n        </li>\n        <li><strong>max_iter</strong> : Comme son nom l’indique, il représente le nombre maximal d’itérations prises pour que les solveurs convergent.</li>\n        <li><strong>multi_class</strong> :\n            <ul>\n                <li><strong>ovr</strong> : Pour cette option, un problème binaire convient à chaque étiquette.</li>\n                <li><strong>multimonial</strong> : Pour cette option, la perte minimisée est l’ajustement de la perte multinomiale sur l’ensemble de la distribution de probabilité. Nous ne pouvons pas utiliser cette option si solver = 'liblinear'.</li>\n                <li><strong>auto</strong> : Cette option sélectionnera 'ovr' si solver = 'liblinear' ou si les données sont binaires, sinon il choisira 'multinomial'.</li>\n            </ul>\n        </li>\n        <li><strong>verbose</strong> : Par défaut, la valeur de ce paramètre est 0, mais pour le solveur liblinear et lbfgs, nous devons définir verbose sur n’importe quel nombre positif.</li>\n        <li><strong>warm_start</strong> : Avec ce paramètre défini sur True, nous pouvons réutiliser la solution de l’appel précédent pour l’adapter en tant qu’initialisation. Si nous choisissons la valeur par défaut, c’est-à-dire faux, cela effacera la solution précédente.</li>\n        <li><strong>n_jobs</strong> : Si multi_class = 'ovr', ce paramètre représente le nombre de cœurs de CPU utilisés lors de la parallélisation sur les classes. Il est ignoré lorsque solver = 'liblinear'.</li>\n        <li><strong>l1_ratio</strong> : Il est utilisé dans le cas où penalty = 'elasticnet'. Il s’agit essentiellement du paramètre de mélange Elastic-Net avec 0 < = l1_ratio > = 1.</li>\n    </ul>\n</div>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\">Nous utiliserons certaines de ces paramètres pour optimiser le modèle.</p>","metadata":{}},{"cell_type":"markdown","source":"<h2 align=\"center\" class=\"alert alert-success\">Optimisation de la performance du modèle</h2>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\">Optimisons la performance du modèle avec RandomizedSearchCV.</p>","metadata":{}},{"cell_type":"code","source":"params = {\n    \"columntransformer__pipeline__polynomialfeatures__degree\" : np.arange(2, 11),\n    \"logisticregression__C\": np.linspace(1, 5, 20),\n    \"logisticregression__dual\": [True, False],\n    \"logisticregression__fit_intercept\": [True, False],\n    \"logisticregression__penalty\": ['l1', 'l2', 'elasticnet', 'none'],\n    \"logisticregression__solver\": [\"lbfgs\", \"saga\"]\n}","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:04:07.868987Z","iopub.execute_input":"2022-01-25T14:04:07.869307Z","iopub.status.idle":"2022-01-25T14:04:07.875286Z","shell.execute_reply.started":"2022-01-25T14:04:07.869263Z","shell.execute_reply":"2022-01-25T14:04:07.87433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\ngrid = RandomizedSearchCV(modele, params, n_iter = 20, scoring = \"f1\", cv = 5)\ngrid.fit(X_train, y_train)\ngrid.best_params_","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:04:07.876377Z","iopub.execute_input":"2022-01-25T14:04:07.877035Z","iopub.status.idle":"2022-01-25T14:04:09.864976Z","shell.execute_reply.started":"2022-01-25T14:04:07.877Z","shell.execute_reply":"2022-01-25T14:04:09.864049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"modele = grid.best_estimator_","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:04:09.866455Z","iopub.execute_input":"2022-01-25T14:04:09.866987Z","iopub.status.idle":"2022-01-25T14:04:09.871929Z","shell.execute_reply.started":"2022-01-25T14:04:09.866938Z","shell.execute_reply":"2022-01-25T14:04:09.871099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"selection_modele.evaluation(modele, \"Logistic\", X_train, X_test, y_train, y_test)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:04:09.873715Z","iopub.execute_input":"2022-01-25T14:04:09.874339Z","iopub.status.idle":"2022-01-25T14:04:13.128692Z","shell.execute_reply.started":"2022-01-25T14:04:09.874292Z","shell.execute_reply":"2022-01-25T14:04:13.127882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 align=\"center\" class=\"alert alert-success\">Compromis entre Sensibilité et Précision</h2>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\">Tracons la courbe de Precision-Recall pour vérifier quel seuil nous permet d'obtenir une assez bonne sensibilité sans pour autant trop diminué la précision.</p>","metadata":{}},{"cell_type":"code","source":"selection_modele.courbe_sensibilite_precision(modele, X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:04:13.129746Z","iopub.execute_input":"2022-01-25T14:04:13.129968Z","iopub.status.idle":"2022-01-25T14:04:13.434942Z","shell.execute_reply.started":"2022-01-25T14:04:13.129941Z","shell.execute_reply":"2022-01-25T14:04:13.434014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\">Nous pouvons choisir un seuil de -4.5 pour obtenir une bonne sensibilité et diminuer la précision à l'inverse.</p>","metadata":{}},{"cell_type":"markdown","source":"<h2 align=\"center\" class=\"alert alert-success\">Conception du modèle final</h2>","metadata":{}},{"cell_type":"code","source":"def modele_finale(modele, X, seuil = 0):\n    \"\"\"Modèle de prédiction basé sur le modèle fourni en paramètre.\n    Args:\n        modele (pipeline): Le modèle choisi\n        X (pandas.DataFrame ou Autres): les données à prédire\n        seuil (float): Le seuil de prédiction\n    \"\"\"\n    return modele.decision_function(X) > seuil","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:04:13.436105Z","iopub.execute_input":"2022-01-25T14:04:13.436306Z","iopub.status.idle":"2022-01-25T14:04:13.440989Z","shell.execute_reply.started":"2022-01-25T14:04:13.436281Z","shell.execute_reply":"2022-01-25T14:04:13.440068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\"><strong>Prédiction et calcul de la sensibilité.</strong></p>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\">Prédiction</p>","metadata":{}},{"cell_type":"code","source":"# Pour un seuil de -4.5\ny_pred = modele_finale(modele, X_test, seuil = -4.5)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:04:13.442446Z","iopub.execute_input":"2022-01-25T14:04:13.442762Z","iopub.status.idle":"2022-01-25T14:04:13.463739Z","shell.execute_reply.started":"2022-01-25T14:04:13.442733Z","shell.execute_reply":"2022-01-25T14:04:13.462292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\">Calcul de la sensibilité</p>","metadata":{}},{"cell_type":"code","source":"recall_score(y_test, y_pred).round(3)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T14:04:13.465831Z","iopub.execute_input":"2022-01-25T14:04:13.467088Z","iopub.status.idle":"2022-01-25T14:04:13.483172Z","shell.execute_reply.started":"2022-01-25T14:04:13.467029Z","shell.execute_reply":"2022-01-25T14:04:13.482194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family:'Times New Roman'\">Nous obtenons ainsi une sensibilité finale tournant autour de <strong>94%</strong></p>","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}